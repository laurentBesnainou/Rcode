iris
str(iris)
library(ggvis)
library(googleVis)
iris %>% googleVis(~Sepal.Length, ~Sepal.Width, fill = ~Species) %>% layer_points()
library(googleVis)
library(dplyr)
iris %>% googleVis(~Sepal.Length, ~Sepal.Width, fill = ~Species) %>% layer_points()
install.packages("ggvis")
library(ggvis)
library(dplyr)
iris %>% googleVis(~Sepal.Length, ~Sepal.Width, fill = ~Species) %>% layer_points()
iris %>% ggvis(~Sepal.Length, ~Sepal.Width, fill = ~Species) %>% layer_points()
table(iris$Species)
summary(iris)
library(class)
normalize <- function(x) {
num <- x - min(x)
denom <- max(x) - min(x)
return (num/denom)
}
irisNomalized <- iris
irisNomalized$Sepal.length <- normalize(iris$Sepal.length)
normalize(iris$Sepal.length)
min(iris$Sepal.length)
library(ggvis)
library(dplyr)
library(class)####### KNN algorithm
min(iris$Sepal.length)
source('~/.active-rstudio-document', echo=TRUE)
iris$Sepal.length
iris
min(iris$Sepal.Length)
irisNomalized$Sepal.length <- normalize(iris$Sepal.Length)
irisNomalized$Sepal.length <- normalize(iris$Sepal.Length)
irisNomalized$Sepal.Width <- normalize(iris$Sepal.Width)
irisNomalized$Petal.Length <- normalize(iris$Petal.Length)
irisNomalized$Petal.Width <- normalize(iris$Petal.Width)
summary(irisNomlized)
irisNomalized
summary(irisNomalized)
irisNomalized <- iris
min(iris$Sepal.Length)
irisNomalized$Sepal.Length <- normalize(iris$Sepal.Length)
irisNomalized$Sepal.Width <- normalize(iris$Sepal.Width)
irisNomalized$Petal.Length <- normalize(iris$Petal.Length)
irisNomalized$Petal.Width <- normalize(iris$Petal.Width)
summary(irisNomalized)
set.seed(1234)
set.seed(1234)
?set.seed
#on constitue es 2 chantillons
ind <- sample(2, nrow(irisNomalized), replace=TRUE, prob=c(0.67, 0.33))
ind
ind <- sample(2, nrow(irisNomalized), replace=TRUE, prob=c(0.67, 0.33))
iris.training <- irisNomalized[ind==1, 1:4]
iris.test <- irisNomalized[ind==2, 1:4]
View(iris.training)
View(iris.training)
View(irisNomalized)
View(irisNomalized)
View(iris.test)
View(iris.test)
iris_pred <- knn(train = iris.training, test = iris.test, cl = iris.trainLabels, k=3)
#données a prédire
iris.trainLabels <- irisNomalized[ind==1, 5]
iris.testLabels <- irisNomalized[ind==2, 5]
iris_pred <- knn(train = iris.training, test = iris.test, cl = iris.trainLabels, k=3)
iris_pred
iris_pred <- knn(train = iris.training, test = iris.test, cl = iris.trainLabels, k=3)
view(iris_pred)
library(gmodels)
install.packages("gmodels")
library(gmodels)
CrossTable(x = iris.testLabels, y = iris_pred, prop.chisq=FALSE)
set.seed(1234)
#on constitue es 2 chantillons (on définit les indice du dataset que l'on veut conserver)
ind <- sample(2, nrow(irisNomalized), replace=TRUE, prob=c(0.67, 0.33))
#données a étudier
iris.training <- irisNomalized[ind==1, 1:4]
iris.test <- irisNomalized[ind==2, 1:4]
#données a prédire
iris.trainLabels <- irisNomalized[ind==1, 5]
iris.testLabels <- irisNomalized[ind==2, 5]
# KNN  k-Nearest Neighbors (Euclidian distance measure )
iris_pred <- knn(train = iris.training, test = iris.test, cl = iris.trainLabels, k=3)
#Evaluation du modèle
CrossTable(x = iris.testLabels, y = iris_pred, prop.chisq=FALSE)
set.seed(1234)
#on constitue es 2 chantillons (on définit les indice du dataset que l'on veut conserver)
ind <- sample(2, nrow(irisNomalized), replace=TRUE, prob=c(0.67, 0.33))
#données a étudier
iris.training <- irisNomalized[ind==1, 1:4]
iris.test <- irisNomalized[ind==2, 1:4]
#données a prédire
iris.trainLabels <- irisNomalized[ind==1, 5]
iris.testLabels <- irisNomalized[ind==2, 5]
# KNN  k-Nearest Neighbors (Euclidian distance measure )
iris_pred <- knn(train = iris.training, test = iris.test, cl = iris.trainLabels, k=3)
#Evaluation du modèle
CrossTable(x = iris.testLabels, y = iris_pred, prop.chisq=FALSE)
lm_wage <- lm(wage ~ age, data = Wage)
sample(35,21)
linkedin <- sample(35,21)
days <- seq(length(linkedin))
linkedin_lm <- lm(linkedin ~ days  )
linkedin_lm
future_days <- data.frame(days = 22:24)
linkedin_pred <- predict(linkedin_lm,future_days)
plot(linkedin ~ days, xlim = c(1, 24))
points(22:24, linkedin_pred, col = "green")
#regression linéaire
linkedin <- sample(35,21)
# Create the days vector
days <- seq(length(linkedin))
# Fit a linear model called on the linkedin views per day: linkedin_lm
linkedin_lm <- lm(linkedin ~ days  )
# Predict the number of views for the next three days: linkedin_pred
future_days <- data.frame(days = 22:24)
linkedin_pred <- predict(linkedin_lm,future_days)
# Plot historical data and predictions
plot(linkedin ~ days, xlim = c(1, 24))
points(22:24, linkedin_pred, col = "green")
#regression linéaire
linkedin <- sample(35,21)
# Create the days vector
days <- seq(length(linkedin))
# Fit a linear model called on the linkedin views per day: linkedin_lm
linkedin_lm <- lm(linkedin ~ days  )
# Predict the number of views for the next three days: linkedin_pred
future_days <- data.frame(days = 22:24)
linkedin_pred <- predict(linkedin_lm,future_days)
# Plot historical data and predictions
plot(linkedin ~ days, xlim = c(1, 24))
points(22:24, linkedin_pred, col = "green")
#regression linéaire
linkedin <- sample(35,21)
# Create the days vector
days <- seq(length(linkedin))
# Fit a linear model called on the linkedin views per day: linkedin_lm
linkedin_lm <- lm(linkedin ~ days  )
# Predict the number of views for the next three days: linkedin_pred
future_days <- data.frame(days = 22:24)
linkedin_pred <- predict(linkedin_lm,future_days)
# Plot historical data and predictions
plot(linkedin ~ days, xlim = c(1, 24))
points(22:24, linkedin_pred, col = "green")
#regression linéaire
linkedin <- sample(35,21)
# Create the days vector
days <- seq(length(linkedin))
# Fit a linear model called on the linkedin views per day: linkedin_lm
linkedin_lm <- lm(linkedin ~ days  )
# Predict the number of views for the next three days: linkedin_pred
future_days <- data.frame(days = 22:24)
linkedin_pred <- predict(linkedin_lm,future_days)
# Plot historical data and predictions
plot(linkedin ~ days, xlim = c(1, 24))
points(22:24, linkedin_pred, col = "green")
#regression linéaire
linkedin <- sample(35,21)
# Create the days vector
days <- seq(length(linkedin))
# Fit a linear model called on the linkedin views per day: linkedin_lm
linkedin_lm <- lm(linkedin ~ days  )
# Predict the number of views for the next three days: linkedin_pred
future_days <- data.frame(days = 22:24)
linkedin_pred <- predict(linkedin_lm,future_days)
# Plot historical data and predictions
plot(linkedin ~ days, xlim = c(1, 24))
points(22:24, linkedin_pred, col = "green")
#regression linéaire
linkedin <- sample(35,21)
# Create the days vector
days <- seq(length(linkedin))
# Fit a linear model called on the linkedin views per day: linkedin_lm
linkedin_lm <- lm(linkedin ~ days  )
# Predict the number of views for the next three days: linkedin_pred
future_days <- data.frame(days = 22:24)
linkedin_pred <- predict(linkedin_lm,future_days)
# Plot historical data and predictions
plot(linkedin ~ days, xlim = c(1, 24))
points(22:24, linkedin_pred, col = "green")
#regression linéaire
linkedin <- sample(35,21)
# Create the days vector
days <- seq(length(linkedin))
# Fit a linear model called on the linkedin views per day: linkedin_lm
linkedin_lm <- lm(linkedin ~ days  )
# Predict the number of views for the next three days: linkedin_pred
future_days <- data.frame(days = 22:24)
linkedin_pred <- predict(linkedin_lm,future_days)
# Plot historical data and predictions
plot(linkedin ~ days, xlim = c(1, 24))
points(22:24, linkedin_pred, col = "green")
#regression linéaire
linkedin <- sample(35,21)
# Create the days vector
days <- seq(length(linkedin))
# Fit a linear model called on the linkedin views per day: linkedin_lm
linkedin_lm <- lm(linkedin ~ days  )
# Predict the number of views for the next three days: linkedin_pred
future_days <- data.frame(days = 22:24)
linkedin_pred <- predict(linkedin_lm,future_days)
# Plot historical data and predictions
plot(linkedin ~ days, xlim = c(1, 24))
points(22:24, linkedin_pred, col = "green")
#regression linéaire
linkedin <- sample(35,21)
# Create the days vector
days <- seq(length(linkedin))
# Fit a linear model called on the linkedin views per day: linkedin_lm
linkedin_lm <- lm(linkedin ~ days  )
# Predict the number of views for the next three days: linkedin_pred
future_days <- data.frame(days = 22:24)
linkedin_pred <- predict(linkedin_lm,future_days)
# Plot historical data and predictions
plot(linkedin ~ days, xlim = c(1, 24))
points(22:24, linkedin_pred, col = "green")
#regression linéaire
linkedin <- sample(35,21)
# Create the days vector
days <- seq(length(linkedin))
# Fit a linear model called on the linkedin views per day: linkedin_lm
linkedin_lm <- lm(linkedin ~ days  )
# Predict the number of views for the next three days: linkedin_pred
future_days <- data.frame(days = 22:24)
linkedin_pred <- predict(linkedin_lm,future_days)
# Plot historical data and predictions
plot(linkedin ~ days, xlim = c(1, 24))
points(22:24, linkedin_pred, col = "green")
#regression linéaire
linkedin <- sample(35,21)
# Create the days vector
days <- seq(length(linkedin))
# Fit a linear model called on the linkedin views per day: linkedin_lm
linkedin_lm <- lm(linkedin ~ days  )
# Predict the number of views for the next three days: linkedin_pred
future_days <- data.frame(days = 22:24)
linkedin_pred <- predict(linkedin_lm,future_days)
# Plot historical data and predictions
plot(linkedin ~ days, xlim = c(1, 24))
points(22:24, linkedin_pred, col = "green")
#regression linéaire
linkedin <- sample(35,21)
# Create the days vector
days <- seq(length(linkedin))
# Fit a linear model called on the linkedin views per day: linkedin_lm
linkedin_lm <- lm(linkedin ~ days  )
# Predict the number of views for the next three days: linkedin_pred
future_days <- data.frame(days = 22:24)
linkedin_pred <- predict(linkedin_lm,future_days)
# Plot historical data and predictions
plot(linkedin ~ days, xlim = c(1, 24))
points(22:24, linkedin_pred, col = "green")
linkedin_pred <- predict(linkedin_lm,future_days)
linkedin_pred <- predict(linkedin_lm,future_days)
linkedin_pred <- predict(linkedin_lm,future_days)
linkedin_pred <- predict(linkedin_lm,future_days)
linkedin_pred <- predict(linkedin_lm,future_days)
linkedin_pred <- predict(linkedin_lm,future_days)
linkedin_pred <- predict(linkedin_lm,future_days)
#Clustering : diviser les points en k groupes
# Set random seed. Don't remove this line.
set.seed(1)
# Chop up iris in my_iris and species
my_iris <- iris[-5]
species <- iris$Species
species
kmeans(my_iris, 3)
table(species, kmeans_iris$cluster)
kmeans_iris <- kmeans(my_iris, 3)
table(species, kmeans_iris$cluster)
species
kmeans_iris$cluster
rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data = iris, method = "class")
library(rpart)
rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data = iris, method = "class")
unseen <- data.frame(Sepal.Length = c(5.3, 7.2),
Sepal.Width = c(2.9, 3.9),
Petal.Length = c(1.7, 5.4),
Petal.Width = c(0.8, 2.3))
Predict(tree,unseen,type="class")
predict(tree,unseen,type="class")
# A decision tree model has been built for you
tree <- rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data = iris, method = "class")
# Predict the label of the unseen observations. Print out the result.
predict(tree,unseen,type="class")
kmeans_iris <- kmeans(my_iris, 3)
readingSkills
install.packages("randomForest")
library(randomForest)
lycee <- read.csv2("https://www.data.gouv.fr/s/resources/indicateurs-de-resultat-des-lycees-denseignement-general-et-technologique/20160401-163749/MEN-DEPP-indicateurs-de-resultats-des-LEGT-2015.csv",
sep = ";", header = TRUE, fileEncoding = "ISO-8859-15", na.strings = c(" ",
"."))
View(lycee)
paste(lycee$Etablissement, lycee$Code.Etablissement)
nometab <- paste(lycee$Etablissement, lycee$Code.Etablissement)
gsub("LYCEE ", "", nometab)
nometab <- paste(lycee$Etablissement, lycee$Code.Etablissement)
nometab <- gsub("LYCEE ", "", nometab)
row.names(lycee) <- nometab
View(lycee)
lycee2 <- select(lycee, Secteur.Public.PU.Privé.PR, Académie, Sructure.pédagogique.en.7.groupes,
Taux.Brut.de.Réussite.Total.séries, Taux.Réussite.Attendu.toutes.séries,
Effectif.de.seconde, Effectif.de.première, Effectif.de.terminale)
View(lycee2)
str(lycee2)
lycee2 <- select(lycee, Secteur.Public.PU.Privé.PR, Académie, Sructure.pédagogique.en.7.groupes,
Taux.Brut.de.Réussite.Total.séries, Taux.Réussite.Attendu.toutes.séries,
Effectif.de.seconde, Effectif.de.première, Effectif.de.terminale) %>%
mutate(Taux.Réussite.Attendu.toutes.séries=as.numeric(Taux.Réussite.Attendu.toutes.séries))
lycee2 <- select(lycee, Secteur.Public.PU.Privé.PR, Académie, Sructure.pédagogique.en.7.groupes,
Taux.Brut.de.Réussite.Total.séries, Taux.Réussite.Attendu.toutes.séries,
Effectif.de.seconde, Effectif.de.première, Effectif.de.terminale) %>%
mutate(Taux.Réussite.Attendu.toutes.séries=as.numeric(Taux.Réussite.Attendu.toutes.séries))
str(lycee2)
fit <- randomForest(Secteur.Public.PU.Privé.PR ~ ., data = lycee2, na.action = na.roughfix)
print(fit)
varImpPlot(fit)
install.packages("tm")
install.packages("SnowballC")
install.packages("wordcloud")
readLines('https://www.anil.org/copropriete-financement-travaux/')
install.packages("rvest")
library("rvest")
readLines('https://www.anil.org/copropriete-financement-travaux/')
scraping_wiki <- read_html("https://www.anil.org/copropriete-financement-travaux")
scraping_wiki
scraping_wiki %>% html_text()
scraping_wiki %>% html_nodes("p") %>% html_text()
scraping_wiki <- read_html("https://www.anil.org/copropriete-financement-travaux")
scraping_wiki %>% html_nodes("p") %>% html_text()
scraping_wiki %>% html_nodes("bodytext") %>% html_text()
scraping_wiki %>% html_nodes("bodytext p") %>% html_text()
scraping_wiki %>% html_nodes("#bodytext") %>% html_text()
?html_nodes
scraping_wiki %>% html_nodes('//h3 | //li | //*[contains(concat( " ", @class, " " ), concat( " ", "bodytext", " " ))] | //*[(@id = "top-link")]')
%>% html_text()
scraping_wiki %>%
html_nodes('//h3 | //li | //*[contains(concat( " ", @class, " " ), concat( " ", "bodytext", " " ))] | //*[(@id = "top-link")]') %>% html_text()
scraping_wiki %>%
html_nodes("h3 , li , .bodytext , #top-link") %>% html_text()
scraping_wiki %>%
html_nodes("h3 li .bodytext #top-link") %>% html_text()
scraping_wiki %>%
html_nodes("h3 , li , .bodytext , #top-link") %>% html_text()
scraping_wiki %>% html_nodes(xpath = "//table//td")
xpath <- '//h3 | //li | //*[contains(concat( " ", @class, " " ), concat( " ", "bodytext", " " ))] | //*[(@id = "top-link")]'
scraping_wiki %>% html_nodes(xpath = xpath)
scraping_wiki %>%
html_nodes(".col-sm-9") %>% html_text()
texte <- scraping_wiki %>%
html_nodes(".col-sm-9") %>% html_text()
